{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12/17/21**\n",
    "\n",
    "The purpose of this notebook is to document construction of a hybrid public/metagenomic database. When looking at results of the different database types, I noticed the individual databases actually identified more bacterial peptides in a few of the samples. So are the bacterial strains present in those samples just not well represented by the sequences in publicly available databases? And would complementing the Tailored databases with sequences from metagenomic sequencing boost bacterial peptide identifications even more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elliot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailoredDBs = getOrderedFiles(Path.cwd().joinpath('../12-16-21_NextflowMSGF_Tailored4_Combined/databases/'), '.fasta')\n",
    "individualDBs = getOrderedFiles(Path.cwd().joinpath('../ShotgunMetagenomics/individual_databases/'), '.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts proteins from dbFile, adding them to the supplied dictionary\n",
    "# Differentiates between contaminant proteins and regular proteins with identical sequences\n",
    "# dictionary key=protein sequence, value=protein object\n",
    "def addProtToDict(dictionary, dbFile):\n",
    "    with open(dbFile, 'r') as database:\n",
    "        rawText = database.read()\n",
    "        dataList = rawText.split('\\n>')\n",
    "        dataList[0] = dataList[0][1:]\n",
    "        del rawText\n",
    "        for sequence in dataList:\n",
    "            newProt = Protein(sequence)\n",
    "            identifier = f'contaminant_{newProt.sequence}' if newProt.isContaminant else newProt.sequence\n",
    "            if not identifier in dictionary.keys():\n",
    "                dictionary[identifier] = newProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through each tailored, then individual database in order and pull out the protein sequences\n",
    "# Combine proteins with identical sequences, prioritizing annotation data from the tailored database\n",
    "# Do not combine contaminant sequences with regular proteins that have identical amino acid sequences\n",
    "proteinHolders = [] # key=protein sequence, value=protein object\n",
    "for i in range(len(SAMPLE_NAMES)):\n",
    "    proteinHolders.append({})\n",
    "    addProtToDict(proteinHolders[i], tailoredDBs[i])\n",
    "    addProtToDict(proteinHolders[i], individualDBs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybridDir = Path.cwd().joinpath('../12-17-21_NextflowMSGF_Combined_Hybrid2/databases/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the initial Hybrid databases to file\n",
    "for i in range(len(SAMPLE_NAMES)):\n",
    "    toWrite = []\n",
    "    for prot in proteinHolders[i].values():\n",
    "        toWrite.append(prot.getEntry())\n",
    "    with open(hybridDir.joinpath(f'{SAMPLE_NAMES[i]}_Hybrid2.fasta'), 'w', newline='') as output:\n",
    "        output.write(''.join(toWrite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the refined hybrid databases\n",
    "unprocessed = getOrderedFiles(Path.cwd().joinpath('../12-17-21_NextflowMSGF_Combined_Hybrid2/output/'), '.tsv')\n",
    "processedPath = Path.cwd().joinpath('../12-17-21_NextflowMSGF_Combined_Hybrid2/output_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapseRepeatRows(unprocessed, processedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = getOrderedFiles(processedPath, '.tsv')\n",
    "hybridDBs = getOrderedFiles(hybridDir, '.fasta')\n",
    "refinedDBPath = Path.cwd().joinpath('../12-17-21_NextflowMSGF_Combined_Hybrid2/databases_refined/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each result/db pair, pull out all the hit proteins in the result file, identify the proteins in the DB, then write them out to a new DB\n",
    "for i in range(len(processed)):\n",
    "    protsToInclude = set()\n",
    "    with processed[i].open(mode='r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            protType = determineHitType(row)\n",
    "            if protType == 'first':\n",
    "                continue\n",
    "            hitProts = getProteinHitList(row)\n",
    "            for hit in hitProts:\n",
    "                if hit.find('XXX_') == -1: # Ignore decoy hits\n",
    "                    protsToInclude.add(hit)\n",
    "    protObjs = {} # key=protID, value=protein object\n",
    "    with open(hybridDBs[i], 'r') as database:\n",
    "        rawText = database.read()\n",
    "        dataList = rawText.split('\\n>')\n",
    "        dataList[0] = dataList[0][1:]\n",
    "        del rawText\n",
    "        for sequence in dataList:\n",
    "            newProt = Protein(sequence)\n",
    "            if newProt.id in protsToInclude:\n",
    "                if newProt.id in protObjs.keys():\n",
    "                    for taxa in newProt.taxa:\n",
    "                        protObjs[newProt.id].addTaxa(taxa)\n",
    "                else:\n",
    "                    protObjs[newProt.id] = newProt\n",
    "    toWrite = []\n",
    "    for prot in protObjs.values():\n",
    "        toWrite.append(prot.getEntry())\n",
    "    with open(refinedDBPath.joinpath(f'{SAMPLE_NAMES[i]}_Hybrid2_Refined.fasta'), 'w', newline='') as output:\n",
    "        output.write(''.join(toWrite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinedOutput = getOrderedFiles(Path.cwd().joinpath('../12-17-21_NextflowMSGF_Combined_Hybrid2/output_refined/'), '.tsv')\n",
    "refinedOutputProcessedDir = Path.cwd().joinpath('../12-17-21_NextflowMSGF_Combined_Hybrid2/output_refined_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapseRepeatRows(refinedOutput, refinedOutputProcessedDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
