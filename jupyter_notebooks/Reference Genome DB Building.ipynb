{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6/29/21**\n",
    "\n",
    "I'm interested in doing a more a more robust analysis of how including all the strains of a species in a database affects search performance. I'm going to build tailored databases for each sample, using only a single genome for each organism. So it will be more useful for others, I'll use the reference genome for each species so I can make inferences about how databases using only reference genomes for the microbes in a sample would compare to using the proteins from all strains.\n",
    "\n",
    "The purpose of this notebook is to document construction of these \"Reference Genome\" databases that also include human/contaminant sequences, and refining them through a two-step search. I'll then do the analysis and comparisons to the Public_Tailored databases in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elliot_utils import *\n",
    "initWithReference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysisPath = Path.cwd().joinpath('analysis_files/reference_genome_db/')\n",
    "sequenceData = Path('C:/Users/emlee/Documents/MSGFp/Sequences/Bacteria/AllNCBI_12-19/')\n",
    "humanFile = Path.cwd().joinpath('../PublicSequences/Human9606_2-6-2019_TrypPigBov.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDBPath = Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/databases/')\n",
    "refinedDBPath = Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/databases_refined/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get species -> reference genome file associations\n",
    "referenceGenomes = {} # key=species name, value=reference strain\n",
    "with analysisPath.joinpath('reference_genomes.csv').open(mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        referenceGenomes[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set()\n",
    "for p in sequenceData.rglob('*'):\n",
    "    if p.suffix == '':\n",
    "        nameArray = p.name.split('_')\n",
    "        names.add(nameArray[0] + ' ' + nameArray[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "referenceFiles = {} # key=species name, value=file path of reference genome .fasta\n",
    "for p in sequenceData.rglob('*'):\n",
    "    if not p.suffix == '.fasta':\n",
    "        continue\n",
    "    with open(p, 'r') as database:\n",
    "        rawText = database.read()\n",
    "        dataList = rawText.split('\\n>')\n",
    "        dataList[0] = dataList[0][1:]\n",
    "        del rawText\n",
    "        newProt = Protein(dataList[0])\n",
    "        taxa = newProt.taxa[0]\n",
    "        taxaArray = taxa.split(' ')\n",
    "        taxaName = taxaArray[0] + ' ' + taxaArray[1]\n",
    "        if taxaName in referenceGenomes.keys():\n",
    "            refStrain = referenceGenomes[taxaName]\n",
    "            if refStrain == 'A' or taxa.find(refStrain) != -1:\n",
    "                referenceFiles[taxaName] = p\n",
    "referenceFiles['Eubacterium sp'] = sequenceData.joinpath('Eubacterium_sp/EubacteriumSp._SAMN10239549.fasta')\n",
    "referenceFiles['Porphyromonas sp'] = sequenceData.joinpath('Porphyromonas_sp/PorphyromonasSp._SAMN03004273.fasta')\n",
    "referenceFiles['Sutterella sp'] = sequenceData.joinpath('Sutterella_sp/SutterellaSp._SAMN11897248.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check I have a reference genome file for each organism in the referenceGenomes dictionary\n",
    "for taxa in referenceGenomes.keys():\n",
    "    if not taxa in referenceFiles.keys():\n",
    "        print(taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the species that go into each sample\n",
    "sampleLists = {} # key=sampleID, value=set of species in the sample\n",
    "with Path.cwd().joinpath('analysis_files/tailored_db_building/Tailored0_1.csv').open(mode='r', encoding='utf-8-sig') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        sampleID = row[0].split('_')[0]\n",
    "        sampleLists[sampleID] = set()\n",
    "        for i in range(1, len(row)):\n",
    "            if row[i] == '':\n",
    "                break\n",
    "            elif row[i] == 'Null':\n",
    "                continue\n",
    "            sampleLists[sampleID].add(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get human and contaminant data from the file\n",
    "humanData = ''\n",
    "with humanFile.open(mode='r') as infile:\n",
    "    humanData = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the initial databases\n",
    "for s in SAMPLE_NAMES:\n",
    "    bacterialProts = {} # key=protein sequence, value=protein object\n",
    "    for species in sampleLists[s]:\n",
    "        if not species in referenceFiles.keys():\n",
    "            continue\n",
    "        with open(referenceFiles[species], 'r') as database:\n",
    "            rawText = database.read()\n",
    "            dataList = rawText.split('\\n>')\n",
    "            dataList[0] = dataList[0][1:]\n",
    "            del rawText\n",
    "            for sequence in dataList:\n",
    "                newProt = Protein(sequence)\n",
    "                if newProt.sequence in bacterialProts.keys():\n",
    "                    bacterialProts[newProt.sequence].addTaxa(newProt.taxa[0])\n",
    "                else:\n",
    "                    bacterialProts[newProt.sequence] = newProt\n",
    "    toWrite = [humanData]\n",
    "    for prot in bacterialProts.values():\n",
    "        toWrite.append(prot.getEntry())\n",
    "    with open(rawDBPath.joinpath(f'{s}_referenceGenome.fasta'), mode='w', newline='') as output:\n",
    "        output.write(''.join(toWrite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the refined reference databases\n",
    "unprocessed = getOrderedFiles(Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/output/'), '.tsv')\n",
    "processedPath = Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/output_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapseRepeatRows(unprocessed, processedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = getOrderedFiles(processedPath, '.tsv')\n",
    "referenceGenomeDBs = getOrderedFiles(rawDBPath, '.fasta')\n",
    "refinedDBPath = Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/databases_refined/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each result/db pair, pull out all the hit proteins in the result file, identify the proteins in the DB, then write them out to a new DB\n",
    "for i in range(len(processed)):\n",
    "    protsToInclude = set()\n",
    "    with processed[i].open(mode='r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            protType = determineIDType(row)\n",
    "            if protType == 'first':\n",
    "                continue\n",
    "            hitProts = getProteinHitList(row, 'all')\n",
    "            for hit in hitProts:\n",
    "                if hit.find('XXX_') == -1: # Ignore decoy hits\n",
    "                    protsToInclude.add(hit)\n",
    "    protObjs = {} # key=protID, value=protein object\n",
    "    with open(referenceGenomeDBs[i], 'r') as database:\n",
    "        rawText = database.read()\n",
    "        dataList = rawText.split('\\n>')\n",
    "        dataList[0] = dataList[0][1:]\n",
    "        del rawText\n",
    "        for sequence in dataList:\n",
    "            newProt = Protein(sequence)\n",
    "            if newProt.id in protsToInclude:\n",
    "                if newProt.id in protObjs.keys():\n",
    "                    for taxa in newProt.taxa:\n",
    "                        protObjs[newProt.id].addTaxa(taxa)\n",
    "                else:\n",
    "                    protObjs[newProt.id] = newProt\n",
    "    toWrite = []\n",
    "    for prot in protObjs.values():\n",
    "        toWrite.append(prot.getEntry())\n",
    "    with open(refinedDBPath.joinpath(f'{SAMPLE_NAMES[i]}_ReferenceGenome_refined.fasta'), 'w', newline='') as output:\n",
    "        output.write(''.join(toWrite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinedOutput = getOrderedFiles(Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/output_refined/'), '.tsv')\n",
    "refinedOutputProcessedDir = Path.cwd().joinpath('../1-12-22_NextflowMSGF_Reference_Combined/output_refined_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapseRepeatRows(refinedOutput, refinedOutputProcessedDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
